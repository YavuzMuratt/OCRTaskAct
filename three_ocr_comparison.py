import cv2
import numpy as np
import pytesseract
import easyocr
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
from PIL import Image
import json
import os
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from datetime import datetime
import re
from difflib import SequenceMatcher
import warnings
warnings.filterwarnings('ignore')

class ThreeOCRComparisonSystem:
    def __init__(self, ground_truth_file="ground_truth.json"):
        """3 OCR karÅŸÄ±laÅŸtÄ±rma sistemi baÅŸlatÄ±cÄ±"""
        self.ground_truth = self.load_ground_truth(ground_truth_file)
        self.results = []
        
        # OCR reader'larÄ± baÅŸlat
        print("OCR modelleri yÃ¼kleniyor...")
        self.easyocr_reader = easyocr.Reader(['en'])
        
        # TrOCR modelini yÃ¼kle
        print("TrOCR modeli yÃ¼kleniyor...")
        self.trocr_processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
        self.trocr_model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')
        print("OCR modelleri yÃ¼klendi!")
        
        # Sadece 2 Ã¶n iÅŸleme yÃ¶ntemi
        self.preprocessing_methods = {
            'original': self.no_preprocessing,
            'contrast_enhancement': self.contrast_enhancement
        }
        
    def load_ground_truth(self, file_path):
        """Ground truth verilerini yÃ¼kle"""
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)['ground_truth']
    
    def no_preprocessing(self, image):
        """HiÃ§bir Ã¶n iÅŸleme yapmadan orijinal gÃ¶rÃ¼ntÃ¼yÃ¼ dÃ¶ndÃ¼r"""
        return image
    
    def contrast_enhancement(self, image):
        """Kontrast artÄ±rma"""
        # CLAHE (Contrast Limited Adaptive Histogram Equalization)
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        return clahe.apply(image)
    
    def extract_text_tesseract(self, image, method='original'):
        """Tesseract ile metin Ã§Ä±karma"""
        # Ã–n iÅŸleme uygula
        processed_image = self.preprocessing_methods[method](image)
        
        # Tesseract konfigÃ¼rasyonu
        custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789().:/- '
        
        # OCR uygula
        data = pytesseract.image_to_data(processed_image, config=custom_config, output_type=pytesseract.Output.DICT)
        
        # SonuÃ§larÄ± iÅŸle
        extracted_texts = []
        for i in range(len(data['text'])):
            if int(data['conf'][i]) > 30:  # GÃ¼ven skoru 30'dan bÃ¼yÃ¼k olanlarÄ± al
                text = data['text'][i].strip()
                if text:
                    x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]
                    conf = data['conf'][i]
                    extracted_texts.append({
                        'text': text,
                        'bbox': (x, y, x + w, y + h),
                        'confidence': conf
                    })
        
        return extracted_texts, processed_image
    
    def extract_text_easyocr(self, image, method='original'):
        """EasyOCR ile metin Ã§Ä±karma"""
        # Ã–n iÅŸleme uygula
        processed_image = self.preprocessing_methods[method](image)
        
        # EasyOCR ile OCR uygula
        results = self.easyocr_reader.readtext(processed_image)
        
        # SonuÃ§larÄ± iÅŸle
        extracted_texts = []
        for (bbox, text, confidence) in results:
            if confidence > 0.3:  # GÃ¼ven skoru 0.3'ten bÃ¼yÃ¼k olanlarÄ± al
                # Bbox formatÄ±nÄ± dÃ¶nÃ¼ÅŸtÃ¼r
                x1, y1 = bbox[0]
                x2, y2 = bbox[2]
                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
                
                extracted_texts.append({
                    'text': text.strip(),
                    'bbox': (x1, y1, x2, y2),
                    'confidence': confidence * 100  # YÃ¼zdeye Ã§evir
                })
        
        return extracted_texts, processed_image
    
    def extract_text_trocr(self, image, method='original'):
        """TrOCR ile metin Ã§Ä±karma"""
        # Ã–n iÅŸleme uygula
        processed_image = self.preprocessing_methods[method](image)
        
        # TrOCR sadece RGB gÃ¶rÃ¼ntÃ¼leri kabul eder, gri tonlama gÃ¶rÃ¼ntÃ¼lerini RGB'ye Ã§evir
        if len(processed_image.shape) == 2:  # Gri tonlama
            processed_image = cv2.cvtColor(processed_image, cv2.COLOR_GRAY2RGB)
        elif len(processed_image.shape) == 3 and processed_image.shape[2] == 3:  # BGR
            processed_image = cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB)
        
        # OpenCV gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ PIL'e Ã§evir
        pil_image = Image.fromarray(processed_image)
        
        # TrOCR ile OCR uygula
        pixel_values = self.trocr_processor(pil_image, return_tensors="pt").pixel_values
        
        # Metin Ã§Ä±kar
        generated_ids = self.trocr_model.generate(pixel_values)
        generated_text = self.trocr_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
        
        # SonuÃ§larÄ± iÅŸle
        extracted_texts = []
        if generated_text.strip():
            # TrOCR tÃ¼m gÃ¶rÃ¼ntÃ¼yÃ¼ tek seferde iÅŸler, bbox bilgisi yok
            # Bu yÃ¼zden tÃ¼m gÃ¶rÃ¼ntÃ¼yÃ¼ bbox olarak alÄ±yoruz
            height, width = processed_image.shape[:2]
            
            extracted_texts.append({
                'text': generated_text.strip(),
                'bbox': (0, 0, width, height),  # TÃ¼m gÃ¶rÃ¼ntÃ¼
                'confidence': 85.0  # TrOCR iÃ§in varsayÄ±lan gÃ¼ven skoru
            })
        
        return extracted_texts, processed_image
    
    def calculate_similarity(self, text1, text2):
        """Ä°ki metin arasÄ±ndaki benzerliÄŸi hesapla"""
        if not text1 or not text2:
            return 0.0
        return SequenceMatcher(None, text1.lower(), text2.lower()).ratio()
    
    def find_best_match(self, extracted_text, ground_truth_values):
        """Ground truth deÄŸerleri arasÄ±nda en iyi eÅŸleÅŸmeyi bul"""
        best_match = None
        best_similarity = 0
        
        for key, value in ground_truth_values.items():
            if value:  # BoÅŸ deÄŸerleri atla
                similarity = self.calculate_similarity(extracted_text, str(value))
                if similarity > best_similarity:
                    best_similarity = similarity
                    best_match = (key, value, similarity)
        
        return best_match
    
    def process_image(self, image_path, method='original', ocr_type='tesseract'):
        """Tek bir gÃ¶rÃ¼ntÃ¼yÃ¼ iÅŸle"""
        # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle
        image = cv2.imread(image_path)
        if image is None:
            print(f"Hata: {image_path} yÃ¼klenemedi")
            return None
        
        # OCR uygula
        if ocr_type == 'tesseract':
            extracted_texts, processed_image = self.extract_text_tesseract(image, method)
        elif ocr_type == 'easyocr':
            extracted_texts, processed_image = self.extract_text_easyocr(image, method)
        else:  # trocr
            extracted_texts, processed_image = self.extract_text_trocr(image, method)
        
        # Ground truth ile karÅŸÄ±laÅŸtÄ±r
        matches = []
        for extracted in extracted_texts:
            best_match = self.find_best_match(extracted['text'], self.ground_truth)
            if best_match and best_match[2] > 0.3:  # %30'dan fazla benzerlik
                matches.append({
                    'extracted_text': extracted['text'],
                    'ground_truth_key': best_match[0],
                    'ground_truth_value': best_match[1],
                    'similarity': best_match[2],
                    'confidence': extracted['confidence'],
                    'bbox': extracted['bbox']
                })
        
        return {
            'image_path': image_path,
            'method': method,
            'ocr_type': ocr_type,
            'extracted_texts': extracted_texts,
            'matches': matches,
            'processed_image': processed_image,
            'original_image': image
        }
    
    def create_visualization(self, result):
        """GÃ¶rsel Ã§Ä±ktÄ± oluÅŸtur"""
        if not result:
            return None
        
        # Orijinal gÃ¶rÃ¼ntÃ¼yÃ¼ kopyala
        vis_image = result['original_image'].copy()
        
        # OCR tipini belirle
        ocr_type = result['ocr_type']
        color_map = {
            'tesseract': (0, 255, 0),    # YeÅŸil
            'easyocr': (255, 0, 0),      # Mavi
            'trocr': (0, 0, 255)         # KÄ±rmÄ±zÄ±
        }
        box_color = color_map.get(ocr_type, (0, 255, 0))
        
        # TÃ¼m okunan metinler iÃ§in bounding box'larÄ± Ã§iz
        for extracted in result['extracted_texts']:
            x1, y1, x2, y2 = extracted['bbox']
            
            # TÃ¼m metinler iÃ§in box Ã§iz
            cv2.rectangle(vis_image, (x1, y1), (x2, y2), box_color, 1)
            
            # Metin ekle
            text = f"{extracted['text']}"
            cv2.putText(vis_image, text, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.3, box_color, 1)
        
        # Ground truth ile eÅŸleÅŸen metinler iÃ§in kalÄ±n box'larÄ± Ã§iz
        for match in result['matches']:
            x1, y1, x2, y2 = match['bbox']
            
            # EÅŸleÅŸen metinler iÃ§in kalÄ±n box Ã§iz
            cv2.rectangle(vis_image, (x1, y1), (x2, y2), (0, 255, 255), 3)  # SarÄ±
            
            # Metin ekle
            text = f"{match['ground_truth_key']}: {match['extracted_text']}"
            cv2.putText(vis_image, text, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
            
            # Benzerlik skorunu da ekle
            similarity_text = f"Benzerlik: {match['similarity']:.2f}"
            cv2.putText(vis_image, similarity_text, (x1, y2+15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
        
        return vis_image
    
    def create_comparison_visualization(self, results_for_image):
        """AynÄ± gÃ¶rÃ¼ntÃ¼ iÃ§in farklÄ± OCR'larÄ±n karÅŸÄ±laÅŸtÄ±rmalÄ± gÃ¶rselleÅŸtirmesi"""
        if not results_for_image:
            return None
        
        # Ä°lk sonucun orijinal gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ al
        original_image = results_for_image[0]['original_image']
        height, width = original_image.shape[:2]
        
        # OCR sayÄ±sÄ±nÄ± hesapla
        num_ocrs = len(results_for_image)
        cols = min(3, num_ocrs)  # Maksimum 3 sÃ¼tun (3 OCR)
        rows = (num_ocrs + cols - 1) // cols
        
        # BÃ¼yÃ¼k bir gÃ¶rÃ¼ntÃ¼ oluÅŸtur
        comparison_image = np.zeros((height * rows, width * cols, 3), dtype=np.uint8)
        
        for idx, result in enumerate(results_for_image):
            row = idx // cols
            col = idx % cols
            
            # GÃ¶rselleÅŸtirme oluÅŸtur
            vis_image = self.create_visualization(result)
            if vis_image is not None:
                # OCR adÄ±nÄ± ekle
                ocr_name = result['ocr_type'].upper()
                method_name = result['method'].upper()
                cv2.putText(vis_image, f"{ocr_name} - {method_name}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                
                # Ä°statistikleri ekle
                stats_text = f"Metin: {len(result['extracted_texts'])} | EÅŸleÅŸme: {len(result['matches'])}"
                cv2.putText(vis_image, stats_text, (10, height-20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                # GÃ¶rÃ¼ntÃ¼yÃ¼ yerleÅŸtir
                y_start = row * height
                y_end = (row + 1) * height
                x_start = col * width
                x_end = (col + 1) * width
                comparison_image[y_start:y_end, x_start:x_end] = vis_image
        
        return comparison_image
    
    def process_all_images(self, images_dir="images"):
        """TÃ¼m gÃ¶rÃ¼ntÃ¼leri iÅŸle"""
        image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        # Her gÃ¶rÃ¼ntÃ¼ iÃ§in tÃ¼m OCR'larÄ±n sonuÃ§larÄ±nÄ± sakla
        image_results = {}
        
        # OCR tipleri
        ocr_types = ['tesseract', 'easyocr', 'trocr']
        
        for ocr_type in ocr_types:
            print(f"\n{ocr_type.upper()} OCR ile iÅŸleniyor...")
            
            for method_name in self.preprocessing_methods.keys():
                print(f"  {method_name.upper()} yÃ¶ntemi...")
                
                for image_file in image_files:
                    image_path = os.path.join(images_dir, image_file)
                    result = self.process_image(image_path, method_name, ocr_type)
                    
                    if result:
                        # GÃ¶rsel Ã§Ä±ktÄ± oluÅŸtur
                        vis_image = self.create_visualization(result)
                        
                        # SonuÃ§larÄ± kaydet
                        self.results.append(result)
                        
                        # GÃ¶rÃ¼ntÃ¼ bazÄ±nda sonuÃ§larÄ± sakla
                        if image_file not in image_results:
                            image_results[image_file] = []
                        image_results[image_file].append(result)
                        
                        # GÃ¶rsel Ã§Ä±ktÄ±yÄ± kaydet
                        if vis_image is not None:
                            output_dir = f"outputs_three_ocr/{ocr_type}/{method_name}"
                            os.makedirs(output_dir, exist_ok=True)
                            
                            vis_path = os.path.join(output_dir, f"vis_{image_file}")
                            cv2.imwrite(vis_path, vis_image)
                            
                            # Ä°ÅŸlenmiÅŸ gÃ¶rÃ¼ntÃ¼yÃ¼ de kaydet
                            processed_path = os.path.join(output_dir, f"processed_{image_file}")
                            cv2.imwrite(processed_path, result['processed_image'])
                            
                            # Ä°ÅŸlenmiÅŸ gÃ¶rÃ¼ntÃ¼de de bounding box'larÄ± gÃ¶ster
                            processed_with_boxes = result['processed_image'].copy()
                            if len(processed_with_boxes.shape) == 2:  # Gri tonlama ise
                                processed_with_boxes = cv2.cvtColor(processed_with_boxes, cv2.COLOR_GRAY2BGR)
                            
                            # TÃ¼m okunan metinler iÃ§in bounding box'larÄ± Ã§iz
                            for extracted in result['extracted_texts']:
                                x1, y1, x2, y2 = extracted['bbox']
                                cv2.rectangle(processed_with_boxes, (x1, y1), (x2, y2), (0, 0, 255), 2)
                            
                            processed_vis_path = os.path.join(output_dir, f"processed_with_boxes_{image_file}")
                            cv2.imwrite(processed_vis_path, processed_with_boxes)
        
        # KarÅŸÄ±laÅŸtÄ±rmalÄ± gÃ¶rselleÅŸtirmeler oluÅŸtur
        print("\nKarÅŸÄ±laÅŸtÄ±rmalÄ± gÃ¶rselleÅŸtirmeler oluÅŸturuluyor...")
        comparison_dir = "outputs_three_ocr/comparisons"
        os.makedirs(comparison_dir, exist_ok=True)
        
        for image_file, results_for_image in image_results.items():
            if len(results_for_image) > 1:  # En az 2 OCR varsa
                comparison_image = self.create_comparison_visualization(results_for_image)
                if comparison_image is not None:
                    comparison_path = os.path.join(comparison_dir, f"comparison_{image_file}")
                    cv2.imwrite(comparison_path, comparison_image)
                    print(f"  KarÅŸÄ±laÅŸtÄ±rma kaydedildi: {comparison_path}")
        
        return self.results
    
    def generate_reports(self):
        """Raporlar oluÅŸtur"""
        # SonuÃ§larÄ± analiz et
        analysis = {}
        
        for result in self.results:
            method = result['method']
            ocr_type = result['ocr_type']
            key = f"{ocr_type}_{method}"
            
            if key not in analysis:
                analysis[key] = {
                    'ocr_type': ocr_type,
                    'method': method,
                    'total_matches': 0,
                    'total_similarity': 0,
                    'total_confidence': 0,
                    'image_count': 0,
                    'matches_by_field': {}
                }
            
            analysis[key]['image_count'] += 1
            analysis[key]['total_matches'] += len(result['matches'])
            
            for match in result['matches']:
                analysis[key]['total_similarity'] += match['similarity']
                analysis[key]['total_confidence'] += match['confidence']
                
                field = match['ground_truth_key']
                if field not in analysis[key]['matches_by_field']:
                    analysis[key]['matches_by_field'][field] = {
                        'count': 0,
                        'avg_similarity': 0,
                        'avg_confidence': 0
                    }
                
                analysis[key]['matches_by_field'][field]['count'] += 1
                analysis[key]['matches_by_field'][field]['avg_similarity'] += match['similarity']
                analysis[key]['matches_by_field'][field]['avg_confidence'] += match['confidence']
        
        # OrtalamalarÄ± hesapla
        for key in analysis:
            if analysis[key]['total_matches'] > 0:
                analysis[key]['avg_similarity'] = analysis[key]['total_similarity'] / analysis[key]['total_matches']
                analysis[key]['avg_confidence'] = analysis[key]['total_confidence'] / analysis[key]['total_matches']
            
            for field in analysis[key]['matches_by_field']:
                count = analysis[key]['matches_by_field'][field]['count']
                if count > 0:
                    analysis[key]['matches_by_field'][field]['avg_similarity'] /= count
                    analysis[key]['matches_by_field'][field]['avg_confidence'] /= count
        
        return analysis
    
    def create_performance_charts(self, analysis):
        """Performans grafikleri oluÅŸtur"""
        # Grafikler iÃ§in veri hazÄ±rla
        keys = list(analysis.keys())
        avg_similarities = [analysis[k]['avg_similarity'] for k in keys]
        avg_confidences = [analysis[k]['avg_confidence'] for k in keys]
        total_matches = [analysis[k]['total_matches'] for k in keys]
        
        # OCR tiplerini ayÄ±r
        tesseract_keys = [k for k in keys if 'tesseract' in k]
        easyocr_keys = [k for k in keys if 'easyocr' in k]
        trocr_keys = [k for k in keys if 'trocr' in k]
        
        # Grafikleri oluÅŸtur
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 12))
        
        # Ortalama benzerlik skorlarÄ±
        x_pos = np.arange(len(keys))
        colors = []
        for k in keys:
            if 'tesseract' in k:
                colors.append('green')
            elif 'easyocr' in k:
                colors.append('blue')
            else:  # trocr
                colors.append('red')
        
        ax1.bar(x_pos, avg_similarities, color=colors)
        ax1.set_title('Ortalama Benzerlik SkorlarÄ± (3 OCR KarÅŸÄ±laÅŸtÄ±rmasÄ±)')
        ax1.set_ylabel('Benzerlik Skoru')
        ax1.set_xticks(x_pos)
        ax1.set_xticklabels(keys, rotation=45, ha='right')
        
        # Ortalama gÃ¼ven skorlarÄ±
        ax2.bar(x_pos, avg_confidences, color=colors)
        ax2.set_title('Ortalama GÃ¼ven SkorlarÄ± (3 OCR KarÅŸÄ±laÅŸtÄ±rmasÄ±)')
        ax2.set_ylabel('GÃ¼ven Skoru')
        ax2.set_xticks(x_pos)
        ax2.set_xticklabels(keys, rotation=45, ha='right')
        
        # Toplam eÅŸleÅŸme sayÄ±larÄ±
        ax3.bar(x_pos, total_matches, color=colors)
        ax3.set_title('Toplam EÅŸleÅŸme SayÄ±larÄ± (3 OCR KarÅŸÄ±laÅŸtÄ±rmasÄ±)')
        ax3.set_ylabel('EÅŸleÅŸme SayÄ±sÄ±')
        ax3.set_xticks(x_pos)
        ax3.set_xticklabels(keys, rotation=45, ha='right')
        
        # OCR tipi bazÄ±nda karÅŸÄ±laÅŸtÄ±rma
        tesseract_avg = np.mean([analysis[k]['avg_similarity'] for k in tesseract_keys]) if tesseract_keys else 0
        easyocr_avg = np.mean([analysis[k]['avg_similarity'] for k in easyocr_keys]) if easyocr_keys else 0
        trocr_avg = np.mean([analysis[k]['avg_similarity'] for k in trocr_keys]) if trocr_keys else 0
        
        ocr_comparison = ['Tesseract', 'EasyOCR', 'TrOCR']
        ocr_scores = [tesseract_avg, easyocr_avg, trocr_avg]
        colors_ocr = ['green', 'blue', 'red']
        
        ax4.bar(ocr_comparison, ocr_scores, color=colors_ocr)
        ax4.set_title('OCR Tipi BazÄ±nda Ortalama Benzerlik')
        ax4.set_ylabel('Ortalama Benzerlik Skoru')
        
        plt.tight_layout()
        plt.savefig('three_ocr_comparison_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        return fig
    
    def save_detailed_report(self, analysis):
        """DetaylÄ± rapor kaydet"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'ground_truth_fields': list(self.ground_truth.keys()),
            'analysis': analysis,
            'summary': {
                'best_tesseract': max([k for k in analysis.keys() if 'tesseract' in k], key=lambda x: analysis[x]['avg_similarity']) if any('tesseract' in k for k in analysis.keys()) else None,
                'best_easyocr': max([k for k in analysis.keys() if 'easyocr' in k], key=lambda x: analysis[x]['avg_similarity']) if any('easyocr' in k for k in analysis.keys()) else None,
                'best_trocr': max([k for k in analysis.keys() if 'trocr' in k], key=lambda x: analysis[x]['avg_similarity']) if any('trocr' in k for k in analysis.keys()) else None,
                'total_images_processed': sum(analysis[k]['image_count'] for k in analysis),
                'total_matches_found': sum(analysis[k]['total_matches'] for k in analysis)
            }
        }
        
        with open('three_ocr_comparison_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # CSV raporu da oluÅŸtur
        report_data = []
        for key, data in analysis.items():
            for field, field_data in data['matches_by_field'].items():
                report_data.append({
                    'OCR_Type': data['ocr_type'],
                    'Method': data['method'],
                    'Field': field,
                    'Match_Count': field_data['count'],
                    'Avg_Similarity': field_data['avg_similarity'],
                    'Avg_Confidence': field_data['avg_confidence']
                })
        
        df = pd.DataFrame(report_data)
        df.to_csv('three_ocr_comparison_report.csv', index=False)
        
        return report

def main():
    """Ana fonksiyon"""
    print("3 OCR KarÅŸÄ±laÅŸtÄ±rma Sistemi BaÅŸlatÄ±lÄ±yor...")
    
    # OCR karÅŸÄ±laÅŸtÄ±rma sistemi oluÅŸtur
    ocr_comparison = ThreeOCRComparisonSystem()
    
    # TÃ¼m gÃ¶rÃ¼ntÃ¼leri iÅŸle
    print("GÃ¶rÃ¼ntÃ¼ler iÅŸleniyor...")
    results = ocr_comparison.process_all_images()
    
    # Analiz yap
    print("Analiz yapÄ±lÄ±yor...")
    analysis = ocr_comparison.generate_reports()
    
    # Grafikleri oluÅŸtur
    print("Grafikler oluÅŸturuluyor...")
    ocr_comparison.create_performance_charts(analysis)
    
    # DetaylÄ± rapor kaydet
    print("Raporlar kaydediliyor...")
    report = ocr_comparison.save_detailed_report(analysis)
    
    print(f"\n{'='*60}")
    print(f"3 OCR KARÅILAÅTIRMA TAMAMLANDI!")
    print(f"{'='*60}")
    
    if report['summary']['best_tesseract']:
        print(f"ğŸ† En iyi Tesseract: {report['summary']['best_tesseract']}")
    if report['summary']['best_easyocr']:
        print(f"ğŸ† En iyi EasyOCR: {report['summary']['best_easyocr']}")
    if report['summary']['best_trocr']:
        print(f"ğŸ† En iyi TrOCR: {report['summary']['best_trocr']}")
    
    print(f"ğŸ“¸ Ä°ÅŸlenen gÃ¶rÃ¼ntÃ¼ sayÄ±sÄ±: {report['summary']['total_images_processed']}")
    print(f"âœ… Bulunan eÅŸleÅŸme sayÄ±sÄ±: {report['summary']['total_matches_found']}")
    
    print(f"\nğŸ“ Ã‡IKTILAR:")
    print(f"  ğŸ“‚ outputs_three_ocr/ klasÃ¶rÃ¼:")
    print(f"    - Her OCR tipi iÃ§in ayrÄ± klasÃ¶r")
    print(f"    - Her yÃ¶ntem iÃ§in ayrÄ± klasÃ¶r")
    print(f"    - vis_[gÃ¶rÃ¼ntÃ¼].png: Bounding box'lÄ± gÃ¶rÃ¼ntÃ¼ler")
    print(f"    - processed_[gÃ¶rÃ¼ntÃ¼].png: Ä°ÅŸlenmiÅŸ gÃ¶rÃ¼ntÃ¼ler")
    print(f"    - processed_with_boxes_[gÃ¶rÃ¼ntÃ¼].png: Ä°ÅŸlenmiÅŸ gÃ¶rÃ¼ntÃ¼ler + box'lar")
    print(f"  ğŸ“‚ outputs_three_ocr/comparisons/ klasÃ¶rÃ¼:")
    print(f"    - comparison_[gÃ¶rÃ¼ntÃ¼].png: 3 OCR karÅŸÄ±laÅŸtÄ±rmasÄ±")
    print(f"  ğŸ“Š Raporlar:")
    print(f"    - three_ocr_comparison_analysis.png (karÅŸÄ±laÅŸtÄ±rma grafikleri)")
    print(f"    - three_ocr_comparison_report.json (detaylÄ± JSON raporu)")
    print(f"    - three_ocr_comparison_report.csv (CSV raporu)")
    
    print(f"\nğŸ¨ GÃ–RSEL Ã‡IKTILAR:")
    print(f"  ğŸŸ¢ YeÅŸil box'lar: Tesseract sonuÃ§larÄ±")
    print(f"  ğŸ”µ Mavi box'lar: EasyOCR sonuÃ§larÄ±")
    print(f"  ğŸ”´ KÄ±rmÄ±zÄ± box'lar: TrOCR sonuÃ§larÄ±")
    print(f"  ğŸŸ¡ SarÄ± box'lar: Ground truth ile eÅŸleÅŸen metinler")

if __name__ == "__main__":
    main() 